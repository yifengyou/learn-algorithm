# 多道批处理调度

题目描述：

某多处理器多道批处理系统一次允许将所有作业调入内存，且能并行执行，其并行数等于处理机个数。该系统采用SJF的调度方式（最短作业优先，系统在调度时，**总是优先调度执行处理时间最短的作业**）。

现给定处理器个数m，作业数n，每个作业的处理时间分别为t1，t2...tn。

当n>m时，首先处理时间短的m个作业进入处理器处理，其他的进入等待，当某个作业处理完成时，依次从等待队列中取处理时间最短的作业进入处理。

求系统处理完所有作业的耗时为多少？

注：不考虑作业切换的消耗。

输入描述：

输入2行，第一行为2个整数（采用空格分隔），分别表示处理器个数m和作业数n；第二行输入n个整数（采用空格分隔），表示每个作业的处理时长t1，t2...tn。

0<m，n<100，0<t1，t2...tn<100。

输出描述：

输出处理总时长

示例1：

输入
```
3  5

8  4  3  1  10
```
输出
```
13
```

## 解析

貌似么有捷径。模拟CPU调度队列就行，问题不大


## Python解法

```
if __name__ == '__main__':
    # m, n = map(int, input().strip().split())
    # joblist = list(map(int,input().strip().split()))
    def findMin(array):
        # print(array)
        min = array[0]
        for item in array:
            if item < min:
                min = item
        return min

    def listSum(array):
        sum = 0
        for item in array:
            sum += item
        return sum

    def findMinCPU(cpuarray):
        cpu_sum_list = []
        for index,cpu in enumerate(cpuarray):
            cpu_sum_list.append(listSum(cpuarray[index]))
        return cpu_sum_list.index(findMin(cpu_sum_list))

    m, n = 2,2
    joblist = [10, 100]
    cpu = []
    for i in range(m):
        cpu.append([0])
    # print("cpu",cpu)
    for i in range(n):
        min = findMin(joblist)
        # print("current min:",min)
        cpu[findMinCPU(cpu)].append(min)
        joblist.remove(min)

    max = 0
    for percpu in cpu:
        if listSum(percpu) > max:
            max = listSum(percpu)
    print(max)
```
